{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spoken Dialogue System Lab: Integrating Rasa with Google Assitant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we want to connect our dialogue system which is developed with Rasa to Google Home. In this way, as with saw previously with Giuliano on Alexa, we are going to exploit Google Assistant for its Automatic Speech Recognition (ASR) & Text-to-Speech (TTS) modules while all the other modules such as NLU,DM & NLG are handled by Rasa.\n",
    "This lab is based on this [blog post](https://blog.rasa.com/going-beyond-hey-google-building-a-rasa-powered-google-assistant/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Preparing Our Rasa Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either practice this lab with the Rasa assistant available in the origin blog post, or edit the one you have practiced with Giuliano. In this notebook, we will get the assistant you connected to Alexa, and connect it to Google Home this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So <b>once again</b>, we need to clone the [repository](https://github.com/giTorto/rasa-restaurantbot) using git, or download the [zip](https://github.com/giTorto/rasa-restaurantbot/archive/master.zip) version.\n",
    "As before, to train your RASA assistant, you can just run the command `rasa train` to train your dialogue system. To test your Dialogue System in the command line, use `rasa shell`.\n",
    "\n",
    "So far it's easy right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Initializing the Google Assistant Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to create a custom skill to use Google’s speech-to-text service. In this way, our custom skill is actually our Rasa assistant. Here is the to-do list:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Login to your google account and go to [Google Actions Console](https://console.actions.google.com/) and create a project by `Add Project` or `New Project`\n",
    "\n",
    "Note: Remember which google account you are using at this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Name your project and pick the language you want your assistant to use. Then Click ‘Create project’. For this Notebook, I called my project `Restaurant Searcher`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Now, you will be asked to choose the category of your project. Scroll down to the bottom of the page and choose ‘Actions SDK’ option. By doing that, you tell your Google Assistant that you will implement your own custom action with a custom NLP and dialogue management system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://blog.rasa.com/content/images/2018/09/2018-09-10_22h15_26.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://blog.rasa.com/content/images/2018/09/2018-09-10_22h15_26.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Once you choose `Actions SDK` and click OK, you should be in the overview page of the project. In the quick setup section, there is the option `Decide how your Action is invoked`. This is where you define the `Display Name` of the assistant for google. So that when You say this name, it activates your Rasa Assistant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://blog.rasa.com/content/images/2018/09/2018-09-10_22h24_02.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://blog.rasa.com/content/images/2018/09/2018-09-10_22h24_02.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, I put the invocation name of `Restaurant Search Bot`.\n",
    "So once again:\n",
    "\n",
    "Project Name: `Restaurant Searcher`\n",
    "\n",
    "Display Name: `Restaurant Search Bot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 3: Creating a Google Assistant action with Rasa as Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create a Google action that invokes our Rasa assistant on user demand and passes all user inputs to Rasa after the skill is invoked. So we need two intents, i.e. `Invocation` intent and `Input Passing` intent.\n",
    "\n",
    "For that, you need to:\n",
    "1) Download gactions (Google Actions) from [Google Docs](https://developers.google.com/assistant/tools/gactions-cli)\n",
    "\n",
    "2) Copy it in your project directory (and convert it to to executable file by `chmod +x gactions`).\n",
    "\n",
    "3) Initialize Google Action Configuration by running `gactions init`\n",
    "\n",
    "This should create a file named `action.json` (Not to be mistaken by `actions.py` which is for your Rasa Assistant)\n",
    "\n",
    "Go to `action.json` and change its content to this below. Read the comments I have written below carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "   \"actions\": [                                          #List of G-Actions that we need to have\n",
    "      {\n",
    "        \"description\": \"Default Welcome Intent\",        #The first action is welcome/Invocation\n",
    "        \"name\": \"MAIN\",\n",
    "        \"fulfillment\": {\n",
    "          \"conversationName\": \"welcome\"\n",
    "        },\n",
    "        \"intent\": {\n",
    "          \"name\": \"actions.intent.MAIN\",\n",
    "          \"trigger\": {\n",
    "            \"queryPatterns\":[\"talk to Restaurant Search Bot\"]  #This is the string that invokes the Assitant\n",
    "          }                                                    # Notice the display name is written here too\n",
    "        }\n",
    "      },\n",
    "\t  {\n",
    "        \"description\": \"Rasa Intent\",                    # Second Action, the Input passing\n",
    "        \"name\": \"TEXT\",\n",
    "        \"fulfillment\": {\n",
    "          \"conversationName\": \"rasa_intent\"\n",
    "        },\n",
    "        \"intent\": {\n",
    "          \"name\": \"actions.intent.TEXT\",\n",
    "          \"trigger\": {\n",
    "            \"queryPatterns\":[]\n",
    "          }\n",
    "        }\n",
    "      }],\n",
    "    \"conversations\": {\n",
    "      \"welcome\": {\n",
    "        \"name\": \"welcome\",\n",
    "        \"url\": \"...\",                        #This field is the address of our rasa, I.e. where to sent the inputs\n",
    "        \"fulfillmentApiVersion\": 2           #WE WILL COME BACK TO IT AT STEP 5\n",
    "    },\n",
    "      \"rasa_intent\": {\n",
    "        \"name\": \"rasa_intent\",\n",
    "        \"url\": \"...\",                        #This field is the address of our rasa, I.e. where to sent the inputs\n",
    "        \"fulfillmentApiVersion\": 2           #WE WILL COME BACK TO IT AT STEP 5\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Creating a Rasa Connector to Google Assitant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So by now you have a Rasa Assistant, and a Google Action that can be connected to a Rasa Assistant to use the ASR and TTS. Now, we should connect the two right?\n",
    "\n",
    "For that, create a file called `ga_connector.py` and copy the code below in it. Read the comments I have written in the code carefully.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging    # These are neseccary libraries we are importing\n",
    "import json\n",
    "from sanic import Blueprint, response\n",
    "from sanic.request import Request\n",
    "from typing import Text, Optional, List, Dict, Any\n",
    "\n",
    "from rasa.core.channels.channel import UserMessage, OutputChannel\n",
    "from rasa.core.channels.channel import InputChannel\n",
    "from rasa.core.channels.channel import CollectingOutputChannel\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class GoogleConnector(InputChannel):\n",
    "    \"\"\"A custom http input channel.\n",
    "    This implementation is the basis for a custom implementation of a chat\n",
    "    frontend. You can customize this to send messages to Rasa Core and\n",
    "    retrieve responses from the agent.\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def name(cls):\n",
    "        return \"google_assistant\"\n",
    "\n",
    "\n",
    "    def blueprint(self, on_new_message):                        # Here, we define the webhook that Google Assistant \n",
    "                                                                # will use to pass the user inputs to Rasa Core,    \n",
    "        google_webhook = Blueprint('google_webhook', __name__)  # collect the responses and send them to Google Assistant\n",
    "\n",
    "        @google_webhook.route(\"/\", methods=['GET'])          \n",
    "        async def health(request):                           # We design a Health route to control the connection \n",
    "            return response.json({\"status\": \"ok\"})           # is established by returning 200 ok message\n",
    "\n",
    "        @google_webhook.route(\"/webhook\", methods=['POST'])\n",
    "        async def receive(request):                          # Then we define the main route for our purpose\n",
    "            payload = request.json\t\n",
    "            intent = payload['inputs'][0]['intent'] \t\t\t\n",
    "            text = payload['inputs'][0]['rawInputs'][0]['query'] \n",
    "            \n",
    "            if intent == 'actions.intent.MAIN':\t #This is the initial message we ask to recieve when the assitant is invoked\n",
    "                message = \"Hello! Welcome to the Rasa-powered Google Assistant, Restaurant Search.\" \t\t\t \n",
    "            else:\n",
    "                out = CollectingOutputChannel()\t\t\t\n",
    "                await on_new_message(UserMessage(text, out))\n",
    "                responses = [m[\"text\"] for m in out.messages]\n",
    "                message = responses[0]\n",
    "            r = {\n",
    "                  \"expectUserResponse\": 'true',\n",
    "                  \"expectedInputs\": [\n",
    "                    {\n",
    "                      \"possibleIntents\": [\n",
    "                        {\n",
    "                          \"intent\": \"actions.intent.TEXT\"   #This is our second intent defined in action.json, remember?\n",
    "                        }\n",
    "                    ],\n",
    "                    \"inputPrompt\": {\n",
    "                      \"richInitialPrompt\": {\n",
    "                        \"items\": [\n",
    "                          {\n",
    "                            \"simpleResponse\": {\n",
    "                              \"textToSpeech\": message,\n",
    "                              \"displayText\": message\n",
    "                              }\n",
    "                            }\n",
    "                          ]\n",
    "                        }\n",
    "                      }\n",
    "                    }\n",
    "                  ]\n",
    "                }\n",
    "            return response.json(r)\t\t\t\t\n",
    "        return google_webhook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Putting all the pieces together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets put all of these together and have a Rasa Powered Google Assistant.\n",
    "Ok lets start!\n",
    "\n",
    "Things to do: \n",
    "\n",
    "1) Go to `credentials.yml` (if you dont have it, create this file in our project directory) and change its content to `ga_connector.GoogleConnector:` (If you are using Giuliano's, it should be `alexa_connector.AlexaConnector:`  )\n",
    "\n",
    "2) Copy [ngrok](https://ngrok.com/) to your project directory and initialize it on a port, say `4747`, by running `./ngrok http 4747`\n",
    "\n",
    "3) Run Rasa on the same port you occupied with ngrok by `rasa run --enable-api -p port` . So since I chose `4747` above, it will be `rasa run --enable-api -p 4747` \n",
    "\n",
    "Now what we did is basically running our Rasa agent on LOCAL port `4747` and asking `ngrok` for a path for this port from outside the local machine. As Giuliano told us, \"Launching this command will create a unique URL that will be visible on your commandline. Copy the HTTPS URL, it should look like https://123abc4d.ngrok.io\"\n",
    "\n",
    "4) Copy the the URL `ngrok` produces, and add `/webhooks/google_assistant/webhook`. So, `https://123abc4d.ngrok.io` becomes `https://123abc4d.ngrok.io/webhooks/google_assistant/webhook`. Then, put this as URL in the fields I marked on `action.json` file we created at step 3. So it will be like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "   \"actions\": [                                          #List of G-Actions that we need to have\n",
    "      {\n",
    "        \"description\": \"Default Welcome Intent\",        #The first action is welcome/Invocation\n",
    "        \"name\": \"MAIN\",\n",
    "        \"fulfillment\": {\n",
    "          \"conversationName\": \"welcome\"\n",
    "        },\n",
    "        \"intent\": {\n",
    "          \"name\": \"actions.intent.MAIN\",\n",
    "          \"trigger\": {\n",
    "            \"queryPatterns\":[\"talk to Restaurant Search Bot\"]  #This is the string that invokes the Assitant\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "\t  {\n",
    "        \"description\": \"Rasa Intent\",                    # Second Action, the Input passing\n",
    "        \"name\": \"TEXT\",\n",
    "        \"fulfillment\": {\n",
    "          \"conversationName\": \"rasa_intent\"\n",
    "        },\n",
    "        \"intent\": {\n",
    "          \"name\": \"actions.intent.TEXT\",\n",
    "          \"trigger\": {\n",
    "            \"queryPatterns\":[]\n",
    "          }\n",
    "        }\n",
    "      }],\n",
    "    \"conversations\": {\n",
    "      \"welcome\": {\n",
    "        \"name\": \"welcome\",\n",
    "        \"url\": \"https://123abc4d.ngrok.io/webhooks/google_assistant/webhook\",                        \n",
    "        \"fulfillmentApiVersion\": 2           \n",
    "    },\n",
    "      \"rasa_intent\": {\n",
    "        \"name\": \"rasa_intent\",\n",
    "        \"url\": \"https://123abc4d.ngrok.io/webhooks/google_assistant/webhook\",           \n",
    "        \"fulfillmentApiVersion\": 2      \n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) On a seperate terminal run your rasa action server \n",
    "\n",
    "6) On another terminal run `gactions update --action_package action.json --project PROJECT_ID` for the variable `PROJECT_ID` go to [Google Cloud Console](https://console.cloud.google.com/) and copy it to the command above. it should be something like `restaurant-search-bot-123456`\n",
    "\n",
    "By running this command, it asks you to access your google account (make sure you use the same account as step 2)\n",
    "Once you grant access and authenticate, it should create a file called `creds.data` and return this:\n",
    "\n",
    "`Your app for the Assistant for project restaurant-search-bot-12345 was successfully updated with your actions. Visit the Actions on Google console to finish registering your app and submit it for review at https://console.actions.google.com/project/restaurant-search-bot-12345/overview`\n",
    "\n",
    "7) Now, run `gactions test --action_package action.json --project PROJECT_ID`. Dont forget to substitude `PROJECT_ID` .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are done, You can test your assistant using your your mobile phone or Google Home devices. Try saying `Hey google, Talk to restaurant search bot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
