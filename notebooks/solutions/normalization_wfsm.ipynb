{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Normalization with Finite State Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __author__: Evgeny A. Stepanov\n",
    "- __e-mail__: stepanov.evgeny.a@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going Character Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization of token in our input requires going from token to character level.\n",
    "The algorithms for this is described [here](http://www.openfst.org/twiki/bin/view/FST/FstExamples). \n",
    "Let's follow the same approach.\n",
    "\n",
    "- Let's first define functions to write *FST* and *symbol table* specifications in OpenFST format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fst_write(fst, fname, fs=\" \"):\n",
    "    with open(fname, 'w') as f:\n",
    "        for arc in fst:\n",
    "            f.write(fs.join(map(str, arc)) + \"\\n\")\n",
    "\n",
    "\n",
    "def st_write(st, fname, fs=\"\\t\"):\n",
    "    with open(fname, 'w') as f:\n",
    "        for symbol, idx in st.items():\n",
    "            f.write(fs.join([symbol, str(idx)]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexicon FST: words-to-chars\n",
    "__Algorithm__:\n",
    "- create FST to translate words to characters (like text to FSA)\n",
    "    - the first arc translates first character to a word\n",
    "    - the rest of arcs translate remaining characters to `<epsilon>`\n",
    "\n",
    "__Requirements__:\n",
    "- *Input*: token symbol table\n",
    "- character symbol table (for compiling FST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Character Symbol Tables\n",
    "Working at character-level implies that we need a character symbol table. Let's create now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def st_ascii():\n",
    "    \"\"\"\n",
    "    create ascii symbol table\n",
    "    \"\"\"\n",
    "    syms = {\"<epsilon>\": 0}\n",
    "    for i in range(128):\n",
    "        char_str = chr(i)\n",
    "        if char_str in string.whitespace:\n",
    "            syms['<space>'] = i\n",
    "        elif char_str in string.ascii_letters:\n",
    "            syms[char_str] = i\n",
    "        elif char_str in string.punctuation:\n",
    "            syms[char_str] = i\n",
    "        elif char_str in string.digits:\n",
    "            syms[char_str] = i\n",
    "        else:\n",
    "            # Assume others are control characters.\n",
    "            syms['<ctrl>'] = i\n",
    "    return syms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_write(st_ascii(), 'chars.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fst_token2char(symbol_table, eps='<epsilon>'):\n",
    "    \"\"\"\n",
    "    create a character-level lexicon from corpus in list of lists format\n",
    "    from OpenFST examples\n",
    "    :param symbol_table: fst symbol table\n",
    "    :param eps: epsilon transition symbol\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    special = {'<epsilon>', '<unk>', '<s>', '</s>'}\n",
    "    s = 0  # state\n",
    "    arcs = []\n",
    "    for line in open(symbol_table, 'r'):\n",
    "        cols = line.split()\n",
    "        if cols[1] == '0':\n",
    "            continue  # epsilon\n",
    "        if cols[0] in special:\n",
    "            continue  # reserved tokens (automatically added)\n",
    "        word = cols[0]\n",
    "        chars = list(word)\n",
    "\n",
    "        for i in range(len(chars)):\n",
    "            if i == 0:\n",
    "                # first character of a word\n",
    "                arcs.append([0, s + 1, chars[i], word])\n",
    "            else:\n",
    "                s += 1\n",
    "                arcs.append([s, s + 1, chars[i], eps])\n",
    "        s += 1  # final state\n",
    "        arcs.append([s])\n",
    "    return arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fst_write(fst_token2char('isyms.txt'), 'lexicon.fst.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "fstcompile \\\n",
    "    --isymbols=chars.txt \\\n",
    "    --osymbols=isyms.txt \\\n",
    "    --keep_isymbols \\\n",
    "    --keep_osymbols \\\n",
    "    lexicon.fst.txt | fstclosure > lexicon.fst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "fstinvert lexicon.fst lexicon.inv.fst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t1\t<epsilon>\t<epsilon>\n",
      "1\t2\twho\tw\n",
      "2\t3\t<epsilon>\th\n",
      "3\t4\t<epsilon>\to\n",
      "4\t5\t<epsilon>\t<epsilon>\n",
      "5\t6\tis\ti\n",
      "6\t7\t<epsilon>\ts\n",
      "7\t8\t<epsilon>\t<epsilon>\n",
      "8\t9\tin\ti\n",
      "9\t10\t<epsilon>\tn\n",
      "10\t11\t<epsilon>\t<epsilon>\n",
      "11\t12\tthe\tt\n",
      "12\t13\t<epsilon>\th\n",
      "13\t14\t<epsilon>\te\n",
      "14\t15\t<epsilon>\t<epsilon>\n",
      "15\t16\tmovie\tm\n",
      "16\t17\t<epsilon>\to\n",
      "17\t18\t<epsilon>\tv\n",
      "18\t19\t<epsilon>\ti\n",
      "19\t20\t<epsilon>\te\n",
      "20\t21\t<epsilon>\t<epsilon>\n",
      "21\t22\tthe\tt\n",
      "22\t23\t<epsilon>\th\n",
      "23\t24\t<epsilon>\te\n",
      "24\t25\t<epsilon>\t<epsilon>\n",
      "25\t26\tcampaign\tc\n",
      "26\t27\t<epsilon>\ta\n",
      "27\t28\t<epsilon>\tm\n",
      "28\t29\t<epsilon>\tp\n",
      "29\t30\t<epsilon>\ta\n",
      "30\t31\t<epsilon>\ti\n",
      "31\t32\t<epsilon>\tg\n",
      "32\t33\t<epsilon>\tn\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "fstcompose sent.fsa lexicon.inv.fst | fstprint --isymbols=isyms.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
